{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcbe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/11 10:14:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('SparkSocket') \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d7bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv('projectData/*').drop(\"label_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1da838",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [column_name.replace('label:', '') for column_name in df.columns if 'label:' in column_name]\n",
    "feature_names = [column_name for column_name in df.columns if 'label:' not in column_name][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d44e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,when\n",
    "from pyspark.sql.types import TimestampType\n",
    "# convert df features types to Integer and Double\n",
    "df = df.withColumn('timestamp', col('timestamp').cast(\"integer\"))\n",
    "for feat_name in feature_names:\n",
    "    df = df.withColumn(feat_name, col(feat_name).cast(\"double\"))\n",
    "for label_name in label_names:\n",
    "    label_name = 'label:' + label_name\n",
    "    df = df.withColumn(label_name, when(col(label_name) == 'nan', None).otherwise(col(label_name).cast(\"integer\")))\n",
    "    #df = df.withColumn(label_name, col('label:' + label_name).cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b54ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_sensor_names_from_features(feature_names):\n",
    "    feat_sensor_names = np.array([None for feat in feature_names]);\n",
    "    for (fi,feat) in enumerate(feature_names):\n",
    "        if feat.startswith('raw_acc'):\n",
    "            feat_sensor_names[fi] = 'Acc';\n",
    "            pass;\n",
    "        elif feat.startswith('proc_gyro'):\n",
    "            feat_sensor_names[fi] = 'Gyro';\n",
    "            pass;\n",
    "        elif feat.startswith('raw_magnet'):\n",
    "            feat_sensor_names[fi] = 'Magnet';\n",
    "            pass;\n",
    "        elif feat.startswith('watch_acceleration'):\n",
    "            feat_sensor_names[fi] = 'WAcc';\n",
    "            pass;\n",
    "        elif feat.startswith('watch_heading'):\n",
    "            feat_sensor_names[fi] = 'Compass';\n",
    "            pass;\n",
    "        elif feat.startswith('location'):\n",
    "            feat_sensor_names[fi] = 'Loc';\n",
    "            pass;\n",
    "        elif feat.startswith('location_quick_features'):\n",
    "            feat_sensor_names[fi] = 'Loc';\n",
    "            pass;\n",
    "        elif feat.startswith('audio_naive'):\n",
    "            feat_sensor_names[fi] = 'Aud';\n",
    "            pass;\n",
    "        elif feat.startswith('audio_properties'):\n",
    "            feat_sensor_names[fi] = 'AP';\n",
    "            pass;\n",
    "        elif feat.startswith('discrete'):\n",
    "            feat_sensor_names[fi] = 'PS';\n",
    "            pass;\n",
    "        elif feat.startswith('lf_measurements'):\n",
    "            feat_sensor_names[fi] = 'LF';\n",
    "            pass;\n",
    "        else:\n",
    "            raise ValueError(\"!!! Unsupported feature name: %s\" % feat);\n",
    "\n",
    "        pass;\n",
    "\n",
    "    return feat_sensor_names;  \n",
    "feat_sensor_names = get_sensor_names_from_features(feature_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41e3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_dataset(full_dataset, senesors_to_use, target_label):\n",
    "    is_from_sensor = np.isin(feat_sensor_names, sensors_to_use);\n",
    "    features_to_use = np.array(feature_names)[is_from_sensor]\n",
    "    label_col = 'label:' + target_label\n",
    "    features_to_use = np.insert(features_to_use, 0,'timestamp')\n",
    "    columns_to_select = np.append(features_to_use, label_col)\n",
    "    return df.select(*full_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8936cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_to_use = ['Acc','WAcc'];\n",
    "target_label = 'FIX_walking';\n",
    "df_selected = get_selected_dataset(df, sensors_to_use, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8fcd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.filter(col('timestamp').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a612e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop lines where the label and timestamp are null\n",
    "df_full = df_full.na.drop(subset=[label_col, 'timestamp'])\n",
    "\n",
    "from pyspark.ml.feature import Imputer, StandardScaler, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Replaces the zero values\n",
    "# https://spark.apache.org/docs/latest/ml-features.html#imputer\n",
    "imputer = Imputer(inputCols=features_to_use, outputCols=features_to_use)\n",
    "# Assemble the features in a vector\n",
    "assembler = VectorAssembler(inputCols=features_to_use, outputCol=\"feats\")\n",
    "# Standarize the data\n",
    "# https://spark.apache.org/docs/latest/ml-features.html#standardscaler\n",
    "scaler = StandardScaler(inputCol=\"feats\", outputCol=\"feats_scaled\")\n",
    "# Logistic regression model\n",
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\\\n",
    "  .setFeaturesCol(\"feats_scaled\")\\\n",
    "  .setLabelCol(label_col)\n",
    "\n",
    "pipeline = Pipeline(stages=[imputer, assembler, scaler,mlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b6704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_full.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca84078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan\n",
    "train.filter(isnan(col(label_col))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5da468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|label:FIX_walking|count(1)|\n",
      "+-----------------+--------+\n",
      "|                1|   15548|\n",
      "|                0|  199192|\n",
      "+-----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train.createOrReplaceTempView('TRAIN')\n",
    "spark.sql('''\n",
    "SELECT `label:FIX_walking`, Count(*)\n",
    "FROM TRAIN\n",
    "GROUP BY `label:FIX_walking`\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fcc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data set is unbalanced => fix it in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff07987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c205f146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Define parameter grid\n",
    "grid = ParamGridBuilder().addGrid(mlr.maxIter, [100, 75]).build()\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\", labelCol=label_col)\n",
    "\n",
    "# Create CrossValidator\n",
    "cross_validator = CrossValidator(estimator=mlr, estimatorParamMaps=grid, evaluator=evaluator,parallelism=2)\n",
    "cross_validator = CrossValidator(estimator=pipeline,\\\n",
    "                                 estimatorParamMaps=grid,\\\n",
    "                                 evaluator=evaluator,\\\n",
    "                                 numFolds=3)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_model = cross_validator.fit(train)\n",
    "\n",
    "# Get best model from cross-validation\n",
    "best_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40cbbd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model.write().save('./spark-pipeline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53a0e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp',\n",
       " 'raw_acc:magnitude_stats:mean',\n",
       " 'raw_acc:magnitude_stats:std',\n",
       " 'raw_acc:magnitude_stats:moment3',\n",
       " 'raw_acc:magnitude_stats:moment4',\n",
       " 'raw_acc:magnitude_stats:percentile25',\n",
       " 'raw_acc:magnitude_stats:percentile50',\n",
       " 'raw_acc:magnitude_stats:percentile75',\n",
       " 'raw_acc:magnitude_stats:value_entropy',\n",
       " 'raw_acc:magnitude_stats:time_entropy',\n",
       " 'raw_acc:magnitude_spectrum:log_energy_band0',\n",
       " 'raw_acc:magnitude_spectrum:log_energy_band1',\n",
       " 'raw_acc:magnitude_spectrum:log_energy_band2',\n",
       " 'raw_acc:magnitude_spectrum:log_energy_band3',\n",
       " 'raw_acc:magnitude_spectrum:log_energy_band4',\n",
       " 'raw_acc:magnitude_spectrum:spectral_entropy',\n",
       " 'raw_acc:magnitude_autocorrelation:period',\n",
       " 'raw_acc:magnitude_autocorrelation:normalized_ac',\n",
       " 'raw_acc:3d:mean_x',\n",
       " 'raw_acc:3d:mean_y',\n",
       " 'raw_acc:3d:mean_z',\n",
       " 'raw_acc:3d:std_x',\n",
       " 'raw_acc:3d:std_y',\n",
       " 'raw_acc:3d:std_z',\n",
       " 'raw_acc:3d:ro_xy',\n",
       " 'raw_acc:3d:ro_xz',\n",
       " 'raw_acc:3d:ro_yz',\n",
       " 'watch_acceleration:magnitude_stats:mean',\n",
       " 'watch_acceleration:magnitude_stats:std',\n",
       " 'watch_acceleration:magnitude_stats:moment3',\n",
       " 'watch_acceleration:magnitude_stats:moment4',\n",
       " 'watch_acceleration:magnitude_stats:percentile25',\n",
       " 'watch_acceleration:magnitude_stats:percentile50',\n",
       " 'watch_acceleration:magnitude_stats:percentile75',\n",
       " 'watch_acceleration:magnitude_stats:value_entropy',\n",
       " 'watch_acceleration:magnitude_stats:time_entropy',\n",
       " 'watch_acceleration:magnitude_spectrum:log_energy_band0',\n",
       " 'watch_acceleration:magnitude_spectrum:log_energy_band1',\n",
       " 'watch_acceleration:magnitude_spectrum:log_energy_band2',\n",
       " 'watch_acceleration:magnitude_spectrum:log_energy_band3',\n",
       " 'watch_acceleration:magnitude_spectrum:log_energy_band4',\n",
       " 'watch_acceleration:magnitude_spectrum:spectral_entropy',\n",
       " 'watch_acceleration:magnitude_autocorrelation:period',\n",
       " 'watch_acceleration:magnitude_autocorrelation:normalized_ac',\n",
       " 'watch_acceleration:3d:mean_x',\n",
       " 'watch_acceleration:3d:mean_y',\n",
       " 'watch_acceleration:3d:mean_z',\n",
       " 'watch_acceleration:3d:std_x',\n",
       " 'watch_acceleration:3d:std_y',\n",
       " 'watch_acceleration:3d:std_z',\n",
       " 'watch_acceleration:3d:ro_xy',\n",
       " 'watch_acceleration:3d:ro_xz',\n",
       " 'watch_acceleration:3d:ro_yz',\n",
       " 'watch_acceleration:spectrum:x_log_energy_band0',\n",
       " 'watch_acceleration:spectrum:x_log_energy_band1',\n",
       " 'watch_acceleration:spectrum:x_log_energy_band2',\n",
       " 'watch_acceleration:spectrum:x_log_energy_band3',\n",
       " 'watch_acceleration:spectrum:x_log_energy_band4',\n",
       " 'watch_acceleration:spectrum:y_log_energy_band0',\n",
       " 'watch_acceleration:spectrum:y_log_energy_band1',\n",
       " 'watch_acceleration:spectrum:y_log_energy_band2',\n",
       " 'watch_acceleration:spectrum:y_log_energy_band3',\n",
       " 'watch_acceleration:spectrum:y_log_energy_band4',\n",
       " 'watch_acceleration:spectrum:z_log_energy_band0',\n",
       " 'watch_acceleration:spectrum:z_log_energy_band1',\n",
       " 'watch_acceleration:spectrum:z_log_energy_band2',\n",
       " 'watch_acceleration:spectrum:z_log_energy_band3',\n",
       " 'watch_acceleration:spectrum:z_log_energy_band4',\n",
       " 'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range0',\n",
       " 'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range1',\n",
       " 'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range2',\n",
       " 'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range3',\n",
       " 'watch_acceleration:relative_directions:avr_cosine_similarity_lag_range4',\n",
       " 'label:FIX_walking']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
